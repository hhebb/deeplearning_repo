{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HEBB\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhhebb\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>\\\\wsl.localhost\\Ubuntu-20.04\\home\\hebb\\ml\\project_hand\\hand_seg\\wandb\\run-20221201_222955-3sen324x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hhebb/ml-project_hand_hand_seg/runs/3sen324x\" target=\"_blank\">ethereal-lake-47</a></strong> to <a href=\"https://wandb.ai/hhebb/ml-project_hand_hand_seg\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hhebb/ml-project_hand_hand_seg/runs/3sen324x?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15eedbef970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "from utils import utils\n",
    "from models.unet import UNet\n",
    "import os\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(),\n",
    "        A.Resize(480, 480),\n",
    "        A.RandomCrop(320, 320),\n",
    "        # A.ColorJitter(brightness=.05, contrast=.05, saturation=.05, hue=.05, p=.2),\n",
    "        A.Affine(translate_percent=.2),\n",
    "        A.Rotate(limit=30),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_valid = A.Compose(\n",
    "    [\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = utils.Dataset_synth(transform)\n",
    "train_set, val_set = torch.utils.data.random_split(ds, [int(len(ds)*.8), len(ds)-int(len(ds)*.8)])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = ds.__getitem__(1)\n",
    "# Image.fromarray(img.numpy().transpose(1, 2, 0).astype(np.uint8)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 320, 320) (320, 320)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = img.numpy()\n",
    "mask = mask.numpy()\n",
    "print(img.shape, mask.shape)\n",
    "# plt.imshow(tmp, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        weights = FCN_ResNet50_Weights.DEFAULT\n",
    "        self.model = fcn_resnet50(num_classes=21) # \n",
    "        self.conv = nn.Conv2d(21, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)['out']\n",
    "        x = self.conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCEDice(pred, gt):\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    bce = criterion(pred, gt)\n",
    "    dice = 1 - get_dice(pred, gt)\n",
    "    loss = bce + dice\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_dice(pred, gt):\n",
    "    eps = 1e-5\n",
    "    summ = torch.sum(gt) + torch.sum(pred)\n",
    "    inter = torch.sum(gt * pred)\n",
    "    dice = 2 * inter / (summ + eps)\n",
    "    \n",
    "    return dice\n",
    "\n",
    "def get_dice_metric(pred, gt):\n",
    "    eps = 1e-5\n",
    "    pred = pred > .5\n",
    "    summ = torch.sum(gt) + torch.sum(pred)\n",
    "    inter = torch.sum(gt * pred)\n",
    "    dice = 2 * inter / (summ + eps)\n",
    "    \n",
    "    return dice\n",
    "    \n",
    "model = Model().cuda()\n",
    "# model = UNet(n_channels=3, n_classes=3).cuda()\n",
    "wandb.watch(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop\n",
    "model.train()\n",
    "for e, epoch in enumerate(range(100)):\n",
    "    total_loss = 0\n",
    "    start = time.time()\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.cuda(), masks.cuda()\n",
    "        pred = model(imgs)\n",
    "        masks = torch.stack([masks for i in range(3)], dim=-1) # \n",
    "        masks = masks.permute(0, 3, 1, 2)\n",
    "\n",
    "        loss = BCEDice(pred, masks)\n",
    "        total_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # logging batch\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        dice = 0\n",
    "        # valid\n",
    "        for batch_idx, (imgs, masks) in enumerate(valid_loader):\n",
    "            imgs, masks = imgs.cuda(), masks.cuda()\n",
    "            masks = torch.stack([masks for i in range(3)], dim=-1) # \n",
    "            masks = masks.permute(0, 3, 1, 2)\n",
    "\n",
    "            pred = model(imgs)\n",
    "            dice += get_dice_metric(pred, masks)\n",
    "\n",
    "            # test output save\n",
    "            if e % 5 == 0:\n",
    "                for sample_idx, pre in enumerate(pred):\n",
    "                    im = imgs[sample_idx]\n",
    "                    im = im.cpu().numpy().transpose(1, 2, 0)\n",
    "                    im = (im * (0.229, 0.224, 0.225) + (0.485, 0.456, 0.406)) * 255\n",
    "                    im = im.astype(np.uint8)\n",
    "                    pred = ((pre.squeeze().detach().cpu().numpy()).transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "\n",
    "                    im = np.clip(im + pred, 0, 255)\n",
    "                    im = Image.fromarray(im)\n",
    "                    save_path = os.path.join(r'\\\\wsl.localhost\\Ubuntu-20.04\\home\\hebb\\ml\\project_hand\\hand_seg\\output\\test', f\"{batch_idx}_{sample_idx}.jpg\")\n",
    "                    im.save(save_path)\n",
    "\n",
    "        # print('dice: ', dice.item() / len(valid_loader), 'total loss: ', total_loss.item() / len(train_loader))\n",
    "        \n",
    "        wandb.log(\n",
    "            {\n",
    "                'dice': dice.item() / len(valid_loader), \n",
    "                'loss': total_loss.item() / len(train_loader),\n",
    "                'elapse': time.time() - start\n",
    "            }\n",
    "        )\n",
    "\n",
    "    torch.save(model.state_dict(), 'ckpt.pt')\n",
    "    # logging epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific directory test\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "eval_path = r'\\\\wsl.localhost\\Ubuntu-20.04\\home\\hebb\\ml\\datasets\\egohand\\_LABELLED_SAMPLES\\PUZZLE_OFFICE_T_S'\n",
    "\n",
    "model = Model().cuda()\n",
    "model.load_state_dict(torch.load('ckpt.pt'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for path in glob(f'{eval_path}\\*'):\n",
    "        if 'frame' not in path:\n",
    "            continue\n",
    "        \n",
    "        img = np.array(Image.open(path))\n",
    "        transformed = torch.unsqueeze(transform_valid(image=img)['image'], 0).cuda()\n",
    "        # transformed = torch.unsqueeze(torch.tensor(img).permute(2, 0, 1), 0).type(torch.float).cuda()\n",
    "        pred = model(transformed)\n",
    "        pred = pred.squeeze().permute(1, 2, 0) > .5\n",
    "        image = Image.fromarray((pred.detach().cpu().numpy()*255).astype(np.uint8))\n",
    "        base = os.path.basename(path)\n",
    "        image.save(f'./output/{base}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "709cd8751d95dd4963018abf8a09bfd0af4b5f2a80d996782d6e3e302b255021"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
