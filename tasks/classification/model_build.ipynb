{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchsummary\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(torch.nn.Module):\n",
    "    def __init__(self, growth_rate=12, num_layers=100, theta=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        num_bottle_layers = (num_layers-4) // 6\n",
    "        self.conv = torch.nn.Conv2d(3, growth_rate*2, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "        self.dense_1 = DenseBlock(in_channels=growth_rate*2, num_layers=num_bottle_layers, growth_rate=growth_rate)\n",
    "        in_trans_1 = growth_rate*2 + growth_rate*num_bottle_layers\n",
    "        self.trans_1 = TransitionBlock(in_channels=in_trans_1, theta=theta)\n",
    "\n",
    "        self.dense_2 = DenseBlock(in_channels=int(in_trans_1*theta), num_layers=num_bottle_layers, growth_rate=growth_rate)\n",
    "        in_trans_2 = int(in_trans_1*theta) + growth_rate*num_bottle_layers\n",
    "        self.trans_2 = TransitionBlock(in_channels=in_trans_2, theta=theta)\n",
    "\n",
    "        self.dense_3 = DenseBlock(in_channels=int(in_trans_2*theta), num_layers=num_bottle_layers, growth_rate=growth_rate)\n",
    "        \n",
    "        in_fc = int(in_trans_2*theta) + growth_rate*num_bottle_layers\n",
    "        self.fc = torch.nn.Linear(in_fc, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_init = self.conv(x)\n",
    "        \n",
    "        print(out_init.shape)\n",
    "        out_dense_1 = self.dense_1(out_init)\n",
    "        out_trans_1 = self.trans_1(out_dense_1)\n",
    "\n",
    "        out_dense_2 = self.dense_2(out_trans_1)\n",
    "        out_trans_2 = self.trans_2(out_dense_2)\n",
    "\n",
    "        out_dense_3 = self.dense_3(out_trans_2)\n",
    "\n",
    "        gap = torch._adaptive_avg_pool2d(out_dense_3)\n",
    "        flatten = torch.flatten(gap)\n",
    "\n",
    "        return flatten\n",
    "\n",
    "\n",
    "class DenseBlock(torch.nn.Sequential):\n",
    "    def __init__(self, in_channels, num_layers, growth_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            in_ch = in_channels + growth_rate * i\n",
    "            self.add_module('bottleneck', BottleNeck(in_ch, growth_rate))\n",
    "\n",
    "\n",
    "class BottleNeck(torch.nn.Sequential):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add_module('conv_1x1', ConvBlock(in_channels, growth_rate*4, kernel=1, stride=1, padding=0))\n",
    "        self.add_module('conv_3x3', ConvBlock(growth_rate*4, growth_rate, kernel=3, stride=1, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = super().forward(x)\n",
    "        out = torch.concat([x, out], dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransitionBlock(torch.nn.Sequential):\n",
    "    def __init__(self, in_channels, theta=0.5):\n",
    "        super().__init__()\n",
    "        self.add_module('conv_1x1', ConvBlock(in_channels, int(in_channels*theta), kernel=1, stride=1, padding=0))\n",
    "        self.add_module('avg_pool', torch.nn.AvgPool2d(2))\n",
    "\n",
    "\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, padding):\n",
    "        super().__init__()\n",
    "        self.bn = torch.nn.BatchNorm2d(in_channels)\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class bn_relu_conv(nn.Module):\n",
    "    def __init__(self, nin, nout, kernel_size, stride, padding, bias=False):\n",
    "        super(bn_relu_conv, self).__init__()\n",
    "        self.batch_norm = nn.BatchNorm2d(nin)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.conv = nn.Conv2d(nin, nout, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.batch_norm(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class bottleneck_layer(nn.Sequential):\n",
    "  def __init__(self, nin, growth_rate, drop_rate=0.2):    \n",
    "      super(bottleneck_layer, self).__init__()\n",
    "      \n",
    "      self.add_module('conv_1x1', bn_relu_conv(nin=nin, nout=growth_rate*4, kernel_size=1, stride=1, padding=0, bias=False))\n",
    "      self.add_module('conv_3x3', bn_relu_conv(nin=growth_rate*4, nout=growth_rate, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "      \n",
    "      self.drop_rate = drop_rate\n",
    "      \n",
    "  def forward(self, x):\n",
    "      bottleneck_output = super(bottleneck_layer, self).forward(x)\n",
    "      if self.drop_rate > 0:\n",
    "          bottleneck_output = torch.dropout(bottleneck_output, p=self.drop_rate, train=self.training)\n",
    "          \n",
    "      bottleneck_output = torch.cat((x, bottleneck_output), 1)\n",
    "      \n",
    "      return bottleneck_output\n",
    "\n",
    "\n",
    "class Transition_layer(nn.Sequential):\n",
    "  def __init__(self, nin, theta=0.5):    \n",
    "      super(Transition_layer, self).__init__()\n",
    "      \n",
    "      self.add_module('conv_1x1', bn_relu_conv(nin=nin, nout=int(nin*theta), kernel_size=1, stride=1, padding=0, bias=False))\n",
    "      self.add_module('avg_pool_2x2', nn.AvgPool2d(kernel_size=2, stride=2, padding=0))\n",
    "\n",
    "\n",
    "class DenseBlock(nn.Sequential):\n",
    "  def __init__(self, nin, num_bottleneck_layers, growth_rate, drop_rate=0.2):\n",
    "      super(DenseBlock, self).__init__()\n",
    "                        \n",
    "      for i in range(num_bottleneck_layers):\n",
    "          nin_bottleneck_layer = nin + growth_rate * i\n",
    "          self.add_module('bottleneck_layer_%d' % i, bottleneck_layer(nin=nin_bottleneck_layer, growth_rate=growth_rate, drop_rate=drop_rate))\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growth_rate=12, num_layers=100, theta=0.5, drop_rate=0.2, num_classes=10):\n",
    "        super(DenseNet, self).__init__()\n",
    "        \n",
    "        assert (num_layers - 4) % 6 == 0\n",
    "        \n",
    "        # (num_layers-4)//6 \n",
    "        num_bottleneck_layers = (num_layers - 4) // 6\n",
    "        \n",
    "        # 32 x 32 x 3 --> 32 x 32 x (growth_rate*2)\n",
    "        self.dense_init = nn.Conv2d(3, growth_rate*2, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "                \n",
    "        # 32 x 32 x (growth_rate*2) --> 32 x 32 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_1 = DenseBlock(nin=growth_rate*2, num_bottleneck_layers=num_bottleneck_layers, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "\n",
    "        # 32 x 32 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)] --> 16 x 16 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)]*theta\n",
    "        nin_transition_layer_1 = (growth_rate*2) + (growth_rate * num_bottleneck_layers) \n",
    "        self.transition_layer_1 = Transition_layer(nin=nin_transition_layer_1, theta=theta)\n",
    "        \n",
    "        # 16 x 16 x nin_transition_layer_1*theta --> 16 x 16 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_2 = DenseBlock(nin=int(nin_transition_layer_1*theta), num_bottleneck_layers=num_bottleneck_layers, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "\n",
    "        # 16 x 16 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)] --> 8 x 8 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)]*theta\n",
    "        nin_transition_layer_2 = int(nin_transition_layer_1*theta) + (growth_rate * num_bottleneck_layers) \n",
    "        self.transition_layer_2 = Transition_layer(nin=nin_transition_layer_2, theta=theta)\n",
    "        \n",
    "        # 8 x 8 x nin_transition_layer_2*theta --> 8 x 8 x [nin_transition_layer_2*theta + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_3 = DenseBlock(nin=int(nin_transition_layer_2*theta), num_bottleneck_layers=num_bottleneck_layers, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        \n",
    "        nin_fc_layer = int(nin_transition_layer_2*theta) + (growth_rate * num_bottleneck_layers) \n",
    "        \n",
    "        # [nin_transition_layer_2*theta + (growth_rate * num_bottleneck_layers)] --> num_classes\n",
    "        self.fc_layer = nn.Linear(nin_fc_layer, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dense_init_output = self.dense_init(x)\n",
    "        \n",
    "        dense_block_1_output = self.dense_block_1(dense_init_output)\n",
    "        transition_layer_1_output = self.transition_layer_1(dense_block_1_output)\n",
    "        \n",
    "        dense_block_2_output = self.dense_block_2(transition_layer_1_output)\n",
    "        transition_layer_2_output = self.transition_layer_2(dense_block_2_output)\n",
    "        \n",
    "        dense_block_3_output = self.dense_block_3(transition_layer_2_output)\n",
    "        \n",
    "        global_avg_pool_output = torch._adaptive_avg_pool2d(dense_block_3_output, (1, 1))                \n",
    "        global_avg_pool_output_flat = global_avg_pool_output.view(global_avg_pool_output.size(0), -1)\n",
    "\n",
    "        output = self.fc_layer(global_avg_pool_output_flat)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GAP\n",
    "# noramlize\n",
    "dummy = torch.rand(size=(4, 3, 224, 224), dtype=torch.float32)\n",
    "model = DenseNet()\n",
    "model(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 81, 81])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = torch.nn.Conv2d(3, 4*2, kernel_size=3, stride=3, padding=10, bias=True)\n",
    "conv(dummy).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dropout() missing 3 required positional argument: \"input\", \"p\", \"train\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hebb/ml/tasks/classification/model_build.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/hebb/ml/tasks/classification/model_build.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mtype\u001b[39m(torch\u001b[39m.\u001b[39;49mdropout())\n",
      "\u001b[0;31mTypeError\u001b[0m: dropout() missing 3 required positional argument: \"input\", \"p\", \"train\""
     ]
    }
   ],
   "source": [
    "type(torch.dropout())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dd979c77fcde639c21f4338339a22090b916d4a09dd85e8db78c65a8dce030e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
